import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.live import Live
from rich.table import Table
from rich.text import Text
from rich import box


class StreamHandler:
    """
    æµå¼äº‹ä»¶å¤„ç†å™¨
    
    æ”¯æŒä¸‰ç§è¾“å‡ºæ¨¡å¼ï¼š
    1. rich: Rich ç¾åŒ–ç»ˆç«¯æ˜¾ç¤ºï¼ˆæµå¼æ¨¡å¼ï¼‰
    2. logger: Logger è¾“å‡ºï¼ˆéæµå¼æ¨¡å¼ï¼‰
    3. structured: ç»“æ„åŒ–å­—å…¸è¾“å‡ºï¼ˆä¸º Gradio é¢„ç•™ï¼‰
    """
    
    def __init__(
        self,
        mode: str = "rich",
        logger: Optional[logging.Logger] = None
        ):
        """
        åˆå§‹åŒ–æµå¼äº‹ä»¶å¤„ç†å™¨
        
        Args:
            mode: è¾“å‡ºæ¨¡å¼ ("rich", "logger", "structured")
            logger: Logger å®ä¾‹ï¼ˆç”¨äºæ–‡ä»¶è®°å½•ï¼‰
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        self.mode = mode
        self.logger = logger
        
        # Rich æ§åˆ¶å°
        if mode == "rich":
            self.console = Console()
        
        # çŠ¶æ€è¿½è¸ª
        self.current_iteration = 0
        self.llm_accumulated_text = ""
        self.tool_call_count = 0
        self.events_history: List[Dict[str, Any]] = []
        
        # äº‹ä»¶ç±»å‹æ˜ å°„
        self.event_type_names = {
            "on_chain_start": "ğŸ”— èŠ‚ç‚¹å¼€å§‹",
            "on_chain_end": "âœ… èŠ‚ç‚¹ç»“æŸ",
            "on_chat_model_start": "ğŸ¤– LLMå¼€å§‹",
            "on_chat_model_stream": "ğŸ’¬ LLMè¾“å‡º",
            "on_chat_model_end": "ğŸ LLMå®Œæˆ",
            "on_tool_start": "ğŸ”§ å·¥å…·è°ƒç”¨å¼€å§‹",
            "on_tool_end": "âœ”ï¸ å·¥å…·è°ƒç”¨å®Œæˆ"
        }
    
    def handle_event(self, event: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†å•ä¸ªäº‹ä»¶
        
        Args:
            event: LangGraph äº‹ä»¶
            
        Returns:
            ç»“æ„åŒ–äº‹ä»¶ï¼ˆstructured æ¨¡å¼ï¼‰ï¼Œå¦åˆ™è¿”å› None
        """
        event_type = event.get("event")
        
        # è®°å½•äº‹ä»¶å†å²
        self.events_history.append(event)
        
        # # åŒæ—¶è®°å½•åˆ° logger
        # if self.logger:
        #     self._log_to_file(event)
        
        # æ ¹æ®æ¨¡å¼å¤„ç†
        if self.mode == "rich":
            self._handle_rich(event)
        elif self.mode == "logger":
            self._handle_logger(event)
        elif self.mode == "structured":
            return self._handle_structured(event)
        
        return None
    
    def _handle_rich(self, event: Dict[str, Any]) -> None:
        """Rich ç¾åŒ–æ˜¾ç¤º"""
        event_type = event.get("event")
        event_name = event.get("name", "")
        event_data = event.get("data", {})
        
        # èŠ‚ç‚¹å¼€å§‹
        if event_type == "on_chain_start":
            if "reasoning" in event_name:
                self.current_iteration += 1
                self.console.print(Panel(
                    f"[bold cyan]è¿­ä»£ {self.current_iteration}[/bold cyan]",
                    title="ğŸ” æ¨ç†èŠ‚ç‚¹",
                    border_style="cyan"
                ))
            elif "force_conclusion" in event_name:
                self.console.print(Panel(
                    "[bold yellow]è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶ç”Ÿæˆç»“è®º[/bold yellow]",
                    title="âš ï¸ å¼ºåˆ¶ç»“è®ºèŠ‚ç‚¹",
                    border_style="yellow"
                ))
            elif "tools" in event_name:
                pass  # å·¥å…·èŠ‚ç‚¹å¼€å§‹ï¼Œç­‰å¾…å…·ä½“å·¥å…·è°ƒç”¨
        
        # èŠ‚ç‚¹ç»“æŸ
        elif event_type == "on_chain_end":
            if "reasoning" in event_name:
                self.console.print(f"[dim]â””â”€ æ¨ç†èŠ‚ç‚¹ç»“æŸ[/dim]\n")
        
        # LLM å¼€å§‹
        elif event_type == "on_chat_model_start":
            self.console.print("[bold blue]ğŸ¤– LLM å¼€å§‹ç”Ÿæˆ...[/bold blue]")
            self.llm_accumulated_text = ""
        
        # LLM Token æµ
        elif event_type == "on_chat_model_stream" or event_type == "on_chain_stream":
            chunk = event_data.get("chunk")
            if hasattr(chunk, "content") and chunk.content:
                token = chunk.content
                self.llm_accumulated_text += token
                # å®æ—¶æ‰“å° token
                self.console.print(token, end="", style="bold white")
        
        # LLM å®Œæˆ
        elif event_type == "on_chat_model_end":
            if self.llm_accumulated_text:
                self.console.print()  # æ¢è¡Œ
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                output = event_data.get("output", {})
                if hasattr(output, "tool_calls") and output.tool_calls:
                    self.console.print(f"\n[bold cyan]ğŸ”§ LLM è¯·æ±‚è°ƒç”¨ {len(output.tool_calls)} ä¸ªå·¥å…·[/bold cyan]")
                elif "ã€è¯Šæ–­ç»“è®ºã€‘" in self.llm_accumulated_text:
                    self.console.print(Panel(
                        self.llm_accumulated_text,
                        title="ğŸ¯ è¯Šæ–­ç»“è®º",
                        border_style="green",
                        box=box.DOUBLE
                    ))
                self.console.print()
        
        # å·¥å…·è°ƒç”¨å¼€å§‹
        elif event_type == "on_tool_start":
            self.tool_call_count += 1
            tool_name = event.get("name", "unknown")
            tool_input = event_data.get("input", {})
            
            self.console.print(Panel(
                self._format_tool_input(tool_input),
                title=f"ğŸ”§ å·¥å…·è°ƒç”¨ #{self.tool_call_count}: {tool_name}",
                border_style="blue"
            ))
        
        # å·¥å…·è°ƒç”¨å®Œæˆ
        elif event_type == "on_tool_end":
            tool_name = event.get("name", "unknown")
            output = event_data.get("output", "").content
            
            # é™åˆ¶è¾“å‡ºé•¿åº¦
            output_str = str(output)
            if len(output_str) > 500:
                output_display = output_str[:500] + "\n..."
            else:
                output_display = output_str
            
            self.console.print(Panel(
                output_display,
                title=f"âœ… å·¥å…·è¿”å›: {tool_name}",
                border_style="green"
            ))
            self.console.print()
    
    def _handle_logger(self, event: Dict[str, Any]) -> None:
        """Logger è¾“å‡ºï¼ˆéæµå¼æ¨¡å¼ï¼‰"""
        if not self.logger:
            return
        
        event_type = event.get("event")
        event_name = event.get("name", "")
        event_data = event.get("data", {})
        
        # åªè®°å½•å…³é”®äº‹ä»¶
        if event_type == "on_chain_start":
            if "reasoning" in event_name:
                self.current_iteration += 1
                self.logger.info(f"æ¨ç†èŠ‚ç‚¹ - è¿­ä»£ {self.current_iteration}")
            elif "force_conclusion" in event_name:
                self.logger.info("å¼ºåˆ¶ç»“è®ºèŠ‚ç‚¹")

        elif event_type == "on_chain_end":
            if "reasoning" in event_name:
                self.logger.info(f"{event_data.get('output', {})['messages'][-1].content}")
            elif "force_conclusion" in event_name:
                self.logger.info("å¼ºåˆ¶ç»“è®ºèŠ‚ç‚¹ç»“æŸ")
        
        elif event_type == "on_tool_start":
            self.tool_call_count += 1
            tool_name = event.get("name", "unknown")
            tool_input = event_data.get("input", {})
            self.logger.info(f"å·¥å…·è°ƒç”¨ #{self.tool_call_count}: {tool_name}")
            self.logger.info(f"{tool_input}")
        
        elif event_type == "on_tool_end":
            tool_name = event.get("name", "unknown")
            self.logger.info(f"å·¥å…·å®Œæˆ: {tool_name}")
            self.logger.info(f"{event_data.get('output', {}).content}")

        
        elif event_type == "on_chat_model_end":
            output = event_data.get("output", {})
            if hasattr(output, "content"):
                content = output.content
                if "ã€è¯Šæ–­ç»“è®ºã€‘" in content:
                    self.logger.info("æ£€æµ‹åˆ°è¯Šæ–­ç»“è®ºè¾“å‡º")
    
    def _handle_structured(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """è¿”å›ç»“æ„åŒ–äº‹ä»¶ï¼ˆä¸º Gradio é¢„ç•™ï¼‰"""
        event_type = event.get("event")
        event_name = event.get("name", "")
        event_data = event.get("data", {})
        
        structured_event = {
            "type": event_type,
            "name": event_name,
            "timestamp": datetime.now().isoformat(),
            "iteration": self.current_iteration
        }
        
        if event_type == "on_tool_start":
            structured_event.update({
                "tool_name": event_name,
                "input": event_data.get("input", {})
            })
        elif event_type == "on_tool_end":
            structured_event.update({
                "tool_name": event_name,
                "output": event_data.get("output", "")
            })
        elif event_type == "on_chat_model_stream":
            chunk = event_data.get("chunk")
            if hasattr(chunk, "content"):
                self.llm_accumulated_text += chunk.content
                structured_event.update({
                    "content": chunk.content,
                    "accumulated": self.llm_accumulated_text
                })
        elif event_type == "on_chat_model_end":
            output = event_data.get("output", {})
            if hasattr(output, "content"):
                structured_event.update({
                    "content": output.content
                })
        
        return structured_event
    
    def _log_to_file(self, event: Dict[str, Any]) -> None:
        """è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶"""
        if not self.logger:
            return
        
        event_type = event.get("event")
        event_name = event.get("name", "")
        event_data = event.get("data", {})
        
        # è¯¦ç»†è®°å½•æ‰€æœ‰äº‹ä»¶åˆ°æ–‡ä»¶
        if event_type == "on_chain_start":
            self.logger.debug(f"[äº‹ä»¶] èŠ‚ç‚¹å¼€å§‹: {event_name}")
        elif event_type == "on_chain_end":
            self.logger.debug(f"[äº‹ä»¶] èŠ‚ç‚¹ç»“æŸ: {event_name}")
        elif event_type == "on_tool_start":
            tool_input = event_data.get("input", {})
            self.logger.info(f"[äº‹ä»¶] å·¥å…·è°ƒç”¨å¼€å§‹: {event_name}, è¾“å…¥: {str(tool_input)[:200]}")
        elif event_type == "on_tool_end":
            output = event_data.get("output", "")
            self.logger.info(f"[äº‹ä»¶] å·¥å…·è°ƒç”¨å®Œæˆ: {event_name}, è¾“å‡ºé•¿åº¦: {len(str(output))}")
        elif event_type == "on_chat_model_stream":
            # Token æµä¸è®°å½•åˆ°æ–‡ä»¶ï¼ˆå¤ªå¤šï¼‰
            pass
        elif event_type == "on_chat_model_end":
            output = event_data.get("output", {})
            if hasattr(output, "content"):
                content = output.content
                self.logger.debug(f"[äº‹ä»¶] LLMå®Œæˆ, è¾“å‡ºé•¿åº¦: {len(content)}")
    
    def _format_tool_input(self, tool_input: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å·¥å…·è¾“å…¥"""
        if not tool_input:
            return "[dim]æ— è¾“å…¥å‚æ•°[/dim]"
        
        # å¦‚æœåŒ…å« SQLï¼Œä½¿ç”¨è¯­æ³•é«˜äº®
        if "sql" in tool_input:
            sql = tool_input.get("sql", "")
            syntax = Syntax(sql, "sql", theme="monokai", line_numbers=False)
            return syntax
        
        # å…¶ä»–æƒ…å†µè¿”å›å­—ç¬¦ä¸²
        return str(tool_input)
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–å¤„ç†æ‘˜è¦"""
        return {
            "total_events": len(self.events_history),
            "iterations": self.current_iteration,
            "tool_calls": self.tool_call_count
        }

